{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP6O7O53I2xvMupdbxAeKnE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yxwwBH-sryeQ"},"outputs":[],"source":["# Part 5 코드 올려놓기 (퍼셉트론)\n","# 런타임 -> 런타임 유형 변경 -> 하드웨어 가속 -> GPU -> 저장\n","# 을 반드시 하고 나서 연결 눌러주세요\n","# 안 그러면 수백배 느림!!!"]},{"cell_type":"code","source":["# 딥러닝 프레임워크\n","# 텐서플로우(케라스)랑 파이토치"],"metadata":{"id":"7o8r2_UZsdbf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch # 라이브러리 이름은 PyTorch\n","from torch import nn # Neural Network (신경망)\n","from torch.utils.data import DataLoader # 데이터로더 기능: (다운로드, 학습/검증 스플릿, 텐서로 변환)\n","# 코드가 좀 Dense하다고 느낄 수 있음\n","# = 짤막한 코드가 수행하는 기능이 여럿이다\n","from torchvision import datasets # 예를 들면 CIFAR-10, COCO, MNIST, Fashion-MNIST, ...\n","# 비전 관련 라이브러리: torchvision\n","# 오디오: torchaudio\n","# 텍스트: torchtext\n","# 강화학습: torch-rl\n","from torchvision.transforms import ToTensor, Compose, Normalize # 배열을 텐서로 바꾸기\n","# torchvision에서 구현되어있는 ToTensor는 이미지를 받아서 텐서로 바꿈\n","# 1. 자료형이 바뀜 -> PIL Image 객체를 텐서로 바꿈\n","# 2. 축 재배열 (transpose 연산) (Height, Width, Channel) -> (Channel, Height, Width)"],"metadata":{"id":"Jo3prRHRs-94"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = Compose([ # 이미지데이터에 적용할 일련의 변환들을 리스트 인자로 받음\n","    ToTensor(),\n","    Normalize((0.0,), (1.0,)) # 정규화 (각 축에 대해서)\n","])"],"metadata":{"id":"HlyB6G7iM9pR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 판다스 실습할 때 root_dir = \"drive/MyDrive/...\"\n","train_data = datasets.FashionMNIST(\n","    root=\"data\", # data란 이름의 폴더에 저장함\n","    train=True, # training 용도인지 boolean으로 주면 됨\n","    download=True, # 다운로드하겠다\n","    transform=transform, # ToTensor 함수로 받은 이미지를 변환해달라\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\", # data란 이름의 폴더에 저장함\n","    train=False, # training 용도인지 boolean으로 주면 됨\n","    download=True, # 다운로드하겠다\n","    transform=transform, # ToTensor 함수로 받은 이미지를 변환해달라\n",")\n","# gzip 프로그램의 압축 결과물 .gz\n","# gzip GNU Zip; GNU -> GNU is Not Unix! # recursive abbreviation\n","# GNU/Unix"],"metadata":{"id":"j41g4IeqvAMj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 64 # mini-batch 경사 하강 -> 프로그래밍할 때는 이 구분을 그대로 따르지 않을 수도 있음\n","# batch_size 64로 해놓고 최적화기법을 SGD로 쓴다든지 할 수 있음\n","\n","# batch_size = 1이면 SGD\n","# batch_size = num_data면 batch 경사 하강\n","train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","# hubo = Robot()\n","# 데이터로더 인스턴스 만듦\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)"],"metadata":{"id":"9fiw7HAZwYMa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터로더는 순회 가능함\n","\n","for X, y in test_dataloader:\n","  print(X.shape, type(X)) # [64, 1, 28, 28] -> N, C, H, W -> N: batch_size; C: channel 갯수; H: height; W: width\n","  print(y.shape, type(y)) # [64] -> batch_size 개의 라벨만 나옴\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_4jsiCJ1q4r","executionInfo":{"status":"ok","timestamp":1689855737476,"user_tz":-540,"elapsed":13,"user":{"displayName":"Andrew Wan Ju Kang","userId":"01898987751291770674"}},"outputId":"0821e1d9-beb6-4284-c394-ed594ed37b04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 1, 28, 28]) <class 'torch.Tensor'>\n","torch.Size([64]) <class 'torch.Tensor'>\n"]}]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","  device = \"cuda\"\n","else:\n","  \"cpu\"\n","# CUDA는 하드웨어 가속 라이브러리\n","# GPU에서 텐서 연산이 빨리 돌게끔 도와줌"],"metadata":{"id":"F_L85SIh3Fhq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 클래스 선언\n","# nn.Module로부터 상속함\n","# nn은 torch 하위 신경망 라이브러리\n","# Module? 신경망 만들으라고 torch에서 구현해놓은 base class\n","# Module의 메서드? 예) forward  입력층에서 텐서를 출력층까지로 보내는 연산\n","\n","# 모델 만들기\n","# FCNN랑 CNN 비교해보자\n","class NeuralNetwork(nn.Module):\n","  def __init__(self):\n","    super().__init__() # 피상속 클래스의 생성자 호출 -> 기초과정 내용 중에 Animal() my_dog = Dog(name=\"Nami\")\n","\n","    self.flatten = nn.Flatten() # nn신경망 라이브러리에 정의되어있는 Flatten 클래스 인스턴스 만들기\n","    # 뭘 납작하게? --> 입력 데이터\n","    # keras.layers에도 Flatten이 있음\n","    # keras.models.Sequential도 있음\n","    # 인자로 층들을 넣어주면 해당 층들을 순차적으로 가지는 (부분)신경망을 만들어줌\n","    self.fcnn = nn.Sequential(\n","        # 예를 들면 폭 512로 만들자\n","        # 28 * 28 = 784\n","        # PCA? 차원 축소 -> explained_variance_ratio\n","        # 28*28은 고정해주세요 (데이터 특성이 이러니까)\n","        nn.Linear(28*28, 512), # torch에서는 Linear라고 불림; keras.layers에서는 Dense라고 불림; 우리 슬라이드에서는 Fully Connected\n","        # 인자로 들어간 두 값 -> 층의 폭. 즉, 28*28=784개의 폭(노드 갯수)를 가진 층과 다음 층(폭이 512인)을 fully connect 하겠다\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","\n","        # 직전 층 폭과 일치하는 512\n","        nn.Linear(512, 128), # 예를 들면 폭 128로 만들자\n","        nn.ReLU(),\n","        nn.Dropout(0.3),\n","\n","        # 직전 층 폭과 일치하는 128\n","        nn.Linear(128, 10) # 10? 클래스 갯수\n","    )\n","\n","  def forward(self, x):\n","    x = self.flatten(x)\n","    logits = self.fcnn(x) # FC층에서 나온 그 값들 자체\n","    # logits 중 가장 큰 값을 가지는 그 위치를 답으로 내겠다는 뜻\n","    # 3개 이상 클래스 분류할 때 softmax를 씀\n","    # 개념적으로는 이진 분류 logistic 활성화 함수의 n개 클래스 확장 버전\n","    # return nn.softmax(logits) 라고 해서 클래스 별 확률을 바로 NeuralNetwork 모델 선언 단에서\n","    # 계산하기도 함\n","    return logits"],"metadata":{"id":"n1i8_6r84GFp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NeuralNetworkStudent1(nn.Module): # 0.8553 기록함 epochs=15, lr=1e-3\n","  def __init__(self):\n","    super().__init__() # 피상속 클래스의 생성자 호출 -> 기초과정 내용 중에 Animal() my_dog = Dog(name=\"Nami\")\n","\n","    self.flatten = nn.Flatten() # nn신경망 라이브러리에 정의되어있는 Flatten 클래스 인스턴스 만들기\n","    # 뭘 납작하게? --> 입력 데이터\n","    # keras.layers에도 Flatten이 있음\n","    # keras.models.Sequential도 있음\n","    # 인자로 층들을 넣어주면 해당 층들을 순차적으로 가지는 (부분)신경망을 만들어줌\n","    self.fcnn = nn.Sequential(\n","        # 예를 들면 폭 512로 만들자\n","        # 28 * 28 = 784\n","        # PCA? 차원 축소 -> explained_variance_ratio\n","        # 28*28은 고정해주세요 (데이터 특성이 이러니까)\n","        nn.Linear(28*28, 512), # torch에서는 Linear라고 불림; keras.layers에서는 Dense라고 불림; 우리 슬라이드에서는 Fully Connected\n","        # 인자로 들어간 두 값 -> 층의 폭. 즉, 28*28=784개의 폭(노드 갯수)를 가진 층과 다음 층(폭이 512인)을 fully connect 하겠다\n","        nn.ReLU(),\n","        nn.BatchNorm1d(512),\n","\n","        # 직전 층 폭과 일치하는 512\n","        nn.Linear(512, 128), # 예를 들면 폭 128로 만들자\n","        nn.ReLU(),\n","\n","\n","        # 직전 층 폭과 일치하는 128\n","        nn.Linear(128, 10) # 10? 클래스 갯수\n","    )\n","\n","  def forward(self, x):\n","    x = self.flatten(x)\n","    logits = self.fcnn(x) # FC층에서 나온 그 값들 자체\n","    # logits 중 가장 큰 값을 가지는 그 위치를 답으로 내겠다는 뜻\n","    # 3개 이상 클래스 분류할 때 softmax를 씀\n","    # 개념적으로는 이진 분류 logistic 활성화 함수의 n개 클래스 확장 버전\n","    # return nn.softmax(logits) 라고 해서 클래스 별 확률을 바로 NeuralNetwork 모델 선언 단에서\n","    # 계산하기도 함\n","    return logits"],"metadata":{"id":"Cru2CrRDBnWX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NeuralNetworkStudent2(nn.Module):\n","  def __init__(self):\n","    super().__init__() # 피상속 클래스의 생성자 호출 -> 기초과정 내용 중에 Animal() my_dog = Dog(name=\"Nami\")\n","\n","    self.flatten = nn.Flatten() # nn신경망 라이브러리에 정의되어있는 Flatten 클래스 인스턴스 만들기\n","    # 뭘 납작하게? --> 입력 데이터\n","    # keras.layers에도 Flatten이 있음\n","    # keras.models.Sequential도 있음\n","    # 인자로 층들을 넣어주면 해당 층들을 순차적으로 가지는 (부분)신경망을 만들어줌\n","    self.fcnn = nn.Sequential(\n","        # 예를 들면 폭 512로 만들자\n","        # 28 * 28 = 784\n","        # PCA? 차원 축소 -> explained_variance_ratio\n","        # 28*28은 고정해주세요 (데이터 특성이 이러니까)\n","        nn.Linear(28*28, 512), # torch에서는 Linear라고 불림; keras.layers에서는 Dense라고 불림; 우리 슬라이드에서는 Fully Connected\n","        # 인자로 들어간 두 값 -> 층의 폭. 즉, 28*28=784개의 폭(노드 갯수)를 가진 층과 다음 층(폭이 512인)을 fully connect 하겠다\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","\n","        # 직전 층 폭과 일치하는 512\n","        nn.Linear(512, 128), # 예를 들면 폭 128로 만들자\n","        nn.ReLU(),\n","\n","        nn.BatchNorm1d(128),\n","        # 직전 층 폭과 일치하는 128\n","        nn.Linear(128, 10) # 10? 클래스 갯수\n","    )\n","\n","  def forward(self, x):\n","    x = self.flatten(x)\n","    logits = self.fcnn(x) # FC층에서 나온 그 값들 자체\n","    # logits 중 가장 큰 값을 가지는 그 위치를 답으로 내겠다는 뜻\n","    # 3개 이상 클래스 분류할 때 softmax를 씀\n","    # 개념적으로는 이진 분류 logistic 활성화 함수의 n개 클래스 확장 버전\n","    # return nn.softmax(logits) 라고 해서 클래스 별 확률을 바로 NeuralNetwork 모델 선언 단에서\n","    # 계산하기도 함\n","    return logits"],"metadata":{"id":"KdK3I2LSCREJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNN(nn.Module):\n","  def __init__(self):\n","    super().__init__() # 피상속 클래스의 생성자 호출 -> 기초과정 내용 중에 Animal() my_dog = Dog(name=\"Nami\")\n","    self.cnn = nn.Sequential(\n","        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1),\n","        # 특성 맵 사이즈: 24\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","        nn.MaxPool2d(kernel_size=2),\n","        # 특성 맵 사이즈: 12\n","        nn.Conv2d(32, out_channels=64, kernel_size=5),\n","        # 특성 맵 사이즈: 8\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","        # 특성 맵 사이즈: 4\n","        nn.Flatten(),\n","        # 텐서 사이즈: 64 * 4 * 4 = 1024\n","        # 직전 층 폭과 일치하는 512\n","        nn.Linear(1024, 128), # 예를 들면 폭 128로 만들자\n","        nn.ReLU(),\n","        nn.BatchNorm1d(128),\n","        # 직전 층 폭과 일치하는 128\n","        nn.Linear(128, 10) # 10? 클래스 갯수\n","    )\n","\n","  def forward(self, x):\n","    logits = self.cnn(x) # FC층에서 나온 그 값들 자체\n","    # logits 중 가장 큰 값을 가지는 그 위치를 답으로 내겠다는 뜻\n","    # 3개 이상 클래스 분류할 때 softmax를 씀\n","    # 개념적으로는 이진 분류 logistic 활성화 함수의 n개 클래스 확장 버전\n","    # return nn.softmax(logits) 라고 해서 클래스 별 확률을 바로 NeuralNetwork 모델 선언 단에서\n","    # 계산하기도 함\n","    return logits"],"metadata":{"id":"qPblN22BC7Eo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNNDemo(nn.Module):\n","  def __init__(self):\n","    super().__init__() # 피상속 클래스의 생성자 호출 -> 기초과정 내용 중에 Animal() my_dog = Dog(name=\"Nami\")\n","    self.cnn = nn.Sequential(\n","        nn.Conv2d(1, 32, 5),\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","        nn.MaxPool2d(kernel_size=2),\n","\n","        nn.Conv2d(32, 64, kernel_size=5),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","\n","        nn.Flatten(),\n","        nn.Linear(1024, 128),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(128),\n","        nn.Linear(128, 10)\n","    )\n","\n","  def forward(self, x):\n","    logits = self.cnn(x) # FC층에서 나온 그 값들 자체\n","    # logits 중 가장 큰 값을 가지는 그 위치를 답으로 내겠다는 뜻\n","    # 3개 이상 클래스 분류할 때 softmax를 씀\n","    # 개념적으로는 이진 분류 logistic 활성화 함수의 n개 클래스 확장 버전\n","    # return nn.softmax(logits) 라고 해서 클래스 별 확률을 바로 NeuralNetwork 모델 선언 단에서\n","    # 계산하기도 함\n","    return logits"],"metadata":{"id":"jixw-8NiHGAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["1152/32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0nK_dHQKAiG","executionInfo":{"status":"ok","timestamp":1689855737478,"user_tz":-540,"elapsed":12,"user":{"displayName":"Andrew Wan Ju Kang","userId":"01898987751291770674"}},"outputId":"e5ab3729-363a-43b7-c32a-9e3408b5e8f3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["36.0"]},"metadata":{},"execution_count":112}]},{"cell_type":"code","source":["# model = NeuralNetwork().to(device)\n","# model = NeuralNetworkStudent1().to(device)\n","# model = NeuralNetworkStudent2().to(device)\n","model = CNNDemo().to(device)\n","\n","# 신경망 인스턴스 만들고 -> CUDA로 \"보냄\" (GPU 상에서 작동할 수 있도록)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QYtHFzTD-PQe","executionInfo":{"status":"ok","timestamp":1689855737478,"user_tz":-540,"elapsed":9,"user":{"displayName":"Andrew Wan Ju Kang","userId":"01898987751291770674"}},"outputId":"46943f3d-7652-4758-ef87-ddd973d4ac67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CNNDemo(\n","  (cnn): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Dropout(p=0.2, inplace=False)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Flatten(start_dim=1, end_dim=-1)\n","    (8): Linear(in_features=1024, out_features=128, bias=True)\n","    (9): ReLU()\n","    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): Linear(in_features=128, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":["######\n","# 모델 튜닝 해보기\n","# epochs\n","# optimizer의 lr 인자\n","# 신경망의 층 구성 (층 갯수, 각 층 폭)\n","# Dropout 어디에 넣을지, dropout rate\n","# BatchNorm1D 어디에 넣을지\n","# CNN에서는: out_channels, stride, kernel_size, pooling"],"metadata":{"id":"wbKENC8r6TCr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습시키기 위해서는\n","# 손실/비용 함수\n","# 최적화기법\n","# 정해줘야 함\n","loss = nn.CrossEntropyLoss() # log loss\n","# SparseCrossEntropyLoss를 쓰면 분류 결과값이 y가 one-hot 인코딩과 비교될 때\n","# sparse 텅 빈 -> 출력 텐서에서 한 값만 1이라\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # 7 * 10^(-4)\n","# SGD: stochastic gradient descent이지만 슬라이드 기준으로는 mini-batch gradient descent (batch_size=64)\n","# 첫번째 인자: 뭘 최적화하는지 -> 모델 파라미터들\n","# 두번째 인자: Learning Rate 잘 모르겠다면 0.001 ~ 0.0001 사이 어디서부턴가 시작하자"],"metadata":{"id":"MPkkk0-BB2ly"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 약간은 기본적인 기능 low-level인 것부터 직접 짜보고\n","# 나중에 편의기능 써보기\n","def train(dataloader, model_, loss_, optimizer_):\n","  # 데이터셋 사이즈\n","  size = len(dataloader.dataset)\n","  model_.train() # 학습 모드로 두겠다 -> 파라미터 값이 갱신되도록 하겠다\n","  # dataloader는 iterable 자료형이니까\n","  # enumerate로 순번(index)이랑 그 위치의 데이터 (X, y) 튜플을 동시에 접근 가능\n","  # dataloader 만들었을 때 이미 batch_size 64 정해줬기 때문에\n","  # dataloader에서 꺼내지는 batch, (X, y) 도 batch_size 개만큼 꺼내짐\n","  for batch, (X, y) in enumerate(dataloader):\n","    X, y = X.to(device), y.to(device) # cuda에 있는 모델에게 \"보내자\"\n","    yhat = model_(X) # nn.Module 클래스 정의에 따라 \"forward\"라 불리는 함수를 직접 호출하지 않아도\n","    # 모델 이름 자체를 함수처럼 쓸 수 있음 -> 그러면 forward가 알아서 호출됨\n","    loss_value = loss_(yhat, y) # 비용 함수 (J) 계산함\n","\n","    # 여기서부터 역전파 (backprop)\n","    loss_value.backward() # 미분값 계산하고, chain rule 적용해서 이전 층의 모든 노드들에게 미분값 전달\n","    # 자동 미분\n","    optimizer_.step() # 최적화 기법에 따라 한 \"걸음\" 파라미터 보정\n","    optimizer_.zero_grad() # 파라미터 보정 한번 했으니까 (이번 batch에 대해서) 이제 초기화\n","\n","    if batch % 500 == 0:\n","      current_loss, current = loss_value.item(), (batch+1) * len(X)\n","      # PyTorch 기준 텐서에서 값만 꺼내서 보고 싶을 때 item() 함수 호출하면 됨\n","      # Pandas DataFrame에서 값(들)만 꺼내서 보고 싶을 때 df.values, df.to_numpy()\n","      # current는 지금 몇번째 데이터를 보고 있는지\n","      print(current_loss, \" at data index \", current)"],"metadata":{"id":"3jOJzqOGDIPS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(dataloader, model_, loss_): # 테스트 단이니까 optimizer가 작동할 일이 없음\n","  # 데이터셋 사이즈\n","  size = len(dataloader.dataset)\n","  num_batches = len(dataloader) # 데이터로더에서 배치 단위로 꺼내왔었음\n","  # 즉, 데이터로더는 배치 갯수만큼의 길이를 가짐\n","  model_.eval() # 검증 모드로 두겠다 -> 파라미터 값이 갱신 안 되도록 하겠다\n","  test_loss, correct = 0, 0 # 검증 단계 비용, 맞힌 문제 갯수\n","  # dataloader는 iterable 자료형이니까\n","  # enumerate로 순번(index)이랑 그 위치의 데이터 (X, y) 튜플을 동시에 접근 가능\n","  # dataloader 만들었을 때 이미 batch_size 64 정해줬기 때문에\n","  # dataloader에서 꺼내지는 batch, (X, y) 도 batch_size 개만큼 꺼내짐\n","\n","  with torch.no_grad(): # 기울기 계산을 안 하겠다\n","    for X, y in dataloader: # 배치 단위로 꺼내기\n","      X, y = X.to(device), y.to(device)\n","      yhat = model_(X)\n","      test_loss += loss_(yhat, y).item() # 누적 비용 계산을 위해 += 연산\n","      # 값만 추적 (텐서 형태 불필요) --> .item() 호출\n","      correct += (yhat.argmax(1) == y).type(torch.float).sum().item()\n","      # 몇 문제 맞혔는지 누계 추적 변수 correct\n","      # 텐서의 메서드 중 argmax는 인자 갯수만큼 상위 값들의 위치를 반환\n","      # y.shape 기억해보세요 -> (60000,) 즉 y는 스칼라 0~9\n","      # yhat은 폭이 10인 텐서임 (신경망 마지막 층 구조 참고)\n","      # 그 텐서에서 가장 값이 큰 1개의 위치(index)가 y와 일치하는지 여부 (True/False)\n","      # 캐스팅 파이썬 기본 문법 (float(2)); pandas.DataFrame(사전)\n","      # 파이토치 캐스팅 문법에 따라 boolean 값을 0(False) 또는 1(True)로 바꿈\n","      # 0 또는 1값을 가진 길이 batch_size인 텐서가 나옴\n","      # 그 텐서 sum을 구하겠다는 뜻은 -> 1 갯수를 세겠다\n","  test_loss /= num_batches # 배치 당 평균 비용\n","  correct /= size\n","  print(\"정답률 \", correct, \" 배치 당 평균 비용 \", test_loss)\n","  # with open(\"파일이름.txt\") as f:\n","    # 이 scope 안에서는 f를 쓰고, scope가 끝나면 f 자동 close() 호출\n","  return"],"metadata":{"id":"zEBMARJLzynt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 10 # 모든 데이터 샘플 한번 보면 epoch\n","for ep in range(epochs):\n","  print(\"Epoch \", ep)\n","  train(train_dataloader, model, loss, optimizer)\n","  test(test_dataloader, model, loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnFsvAnTGqlx","executionInfo":{"status":"ok","timestamp":1689855925971,"user_tz":-540,"elapsed":188499,"user":{"displayName":"Andrew Wan Ju Kang","userId":"01898987751291770674"}},"outputId":"e6fc9fc6-cb52-40d9-dd6e-4546935906b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch  0\n","2.561415910720825  at data index  64\n","0.8183695077896118  at data index  32064\n","정답률  0.7921  배치 당 평균 비용  0.7493315612434581\n","Epoch  1\n","0.6013126969337463  at data index  64\n","0.6357166767120361  at data index  32064\n","정답률  0.8254  배치 당 평균 비용  0.6045353799868541\n","Epoch  2\n","0.4685196578502655  at data index  64\n","0.5583020448684692  at data index  32064\n","정답률  0.834  배치 당 평균 비용  0.539679508869815\n","Epoch  3\n","0.3949597477912903  at data index  64\n","0.5390070080757141  at data index  32064\n","정답률  0.8528  배치 당 평균 비용  0.4836218218514874\n","Epoch  4\n","0.3450136184692383  at data index  64\n","0.49453479051589966  at data index  32064\n","정답률  0.8574  배치 당 평균 비용  0.45785979765235996\n","Epoch  5\n","0.3131885230541229  at data index  64\n","0.45866042375564575  at data index  32064\n","정답률  0.8578  배치 당 평균 비용  0.44125552807643914\n","Epoch  6\n","0.28596219420433044  at data index  64\n","0.4273832142353058  at data index  32064\n","정답률  0.8652  배치 당 평균 비용  0.41584788538088463\n","Epoch  7\n","0.2819063067436218  at data index  64\n","0.3981167674064636  at data index  32064\n","정답률  0.8696  배치 당 평균 비용  0.3967950211209097\n","Epoch  8\n","0.27222582697868347  at data index  64\n","0.39345499873161316  at data index  32064\n","정답률  0.8697  배치 당 평균 비용  0.38947881169759546\n","Epoch  9\n","0.2702266573905945  at data index  64\n","0.38236474990844727  at data index  32064\n","정답률  0.87  배치 당 평균 비용  0.3823413464483941\n"]}]}]}